{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please add your name and University of Michagan uniqname here...\n",
    "\n",
    "NAME = 'Aseem Sachdeva'\n",
    "UMICH_UNIQNAME = 'aseemsa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "828bc331fb4b474c4dc318c79e21c858",
     "grade": false,
     "grade_id": "cell-5a2075c6fc8553e4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v2.3.060120\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "409f037ad73b24de5435ca5034e81b2f",
     "grade": false,
     "grade_id": "cell-7dd8dd131b0c6a5d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# SIADS 515 Week 4 Homework (HW4)\n",
    "\n",
    "## Background\n",
    "\n",
    "The motivation for this assignment is to **improve the efficiency of code** that finds the similarity between any two given documents.  There are many ways to calculate similarity (or distance) between two documents, but the most effective way is to represent each document as a multi-dimensional vector where each dimension corresponds to a word, and the value along that dimension is the number of times that word occurs in a document.  Let's take a look at a simplified case where we only have two dimensions:\n",
    "\n",
    "![](assets/CosineDistanceSimilarity.png)\n",
    "\n",
    "In the above diagram, Item 1 and Item 2 refer to two documents.  The angle between them (𝛳) can range from -180 to +180 degrees.  The cosine of angles, in this case, has a nice property in that the cosine of an angle of 0 degrees is 1, the cosine of an angle of 90 degrees is 0, and the cosine of an angle of 180 degrees is -1.  In other words, the cosine of the angle between the vector representation of a document behaves much like a correlation coefficient.  A cosine of 1 indicates the documents are identical, a cosine of 0 indicates the documents are independent of each other, and a cosine of -1 indicates the documents are \"opposites\" (note: the latter requires a specific setup that is beyond the scope of this course).\n",
    "\n",
    "Your task, for this assignment, is to improve the efficiency of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "523ea2670f08a68ece190b1283069754",
     "grade": false,
     "grade_id": "cell-4775a39fe80a7d8a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Steps\n",
    "\n",
    "1. Run the notebook as it is.\n",
    "1. Study each function in the code, making notes to yourself in preparation for the next step.  \n",
    "1. Annotate each function with a detailed description of what the input and output parameters are.  Provide a brief description, in your own words, of what each function does.  Use docstrings ([PEP-257](https://www.python.org/dev/peps/pep-0257/)) to document the code.\n",
    "1. Make changes to the code to improve its efficiency. \n",
    "\n",
    "Note\n",
    "  - You may [refactor](https://en.wikipedia.org/wiki/Code_refactoring) to combine functions or make other changes if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist1.py\n",
    "# Original author: Ronald L. Rivest\n",
    "# Some adaptation by Chris Teplovs and Kevyn Collins-Thompson\n",
    "#\n",
    "#\n",
    "# This program computes the \"distance\" between two text files\n",
    "# as the angle between their word frequency vectors.\n",
    "#\n",
    "# For each input file, a word-frequency vector is computed as follows:\n",
    "#    (1) the specified file is read in\n",
    "#    (2) it is converted into a list of alphanumeric \"words\"\n",
    "#        Here a \"word\" is a sequence of consecutive alphanumeric\n",
    "#        characters.  Non-alphanumeric characters are treated as blanks.\n",
    "#        Case is not significant.\n",
    "#    (3) for each word, its frequency of occurrence is determined\n",
    "#    (4) the word/frequency lists are sorted into order alphabetically\n",
    "#\n",
    "# The \"distance\" between two vectors is the angle between them.\n",
    "# If x = (x1, x2, ..., xn) is the first vector (xi = freq of word i)\n",
    "# and y = (y1, y2, ..., yn) is the second vector,\n",
    "# then the angle between them is defined as:\n",
    "#    d(x,y) = arccos(inner_product(x,y) / (norm(x)*norm(y)))\n",
    "# where:\n",
    "#    inner_product(x,y) = x1*y1 + x2*y2 + ... xn*yn\n",
    "#    norm(x) = sqrt(inner_product(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "    # math.acos(x) is the arccosine of x.\n",
    "    # math.sqrt(x) is the square root of x.\n",
    "\n",
    "import string\n",
    "    # string.join(words,sep) takes a given list of words,\n",
    "    #    and returns a single string resulting from concatenating them\n",
    "    #    together, separated by the string sep .\n",
    "    # string.lower(word) converts word to lower-case\n",
    "\n",
    "import sys\n",
    "    # sys.exit() allows us to quit (if we can't read a file)\n",
    "    \n",
    "import itertools\n",
    "\n",
    "import collections\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from itertools import chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Operation 1: read a text file ##\n",
    "##################################\n",
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    Read the text file with the given filename.\n",
    "    \n",
    "    :param filename: the name of the text file to be read in\n",
    "    :return: a list of the lines of text in the file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fp = open(filename)\n",
    "        L = fp.readlines()\n",
    "    except IOError as excObj:\n",
    "        print(str(excObj))\n",
    "        print(\"Error opening or reading input file: \" + filename)\n",
    "        sys.exit()\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Operation 2: split the text lines into words ##\n",
    "#################################################\n",
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    \n",
    "    :param L: the list of text lines\n",
    "    :return: list of all words found.\n",
    "    \"\"\"\n",
    "#     words_in_line = [get_words_from_string(line) for line in L] \n",
    "#     word_list = list(chain(*words_in_line))\n",
    "#     return word_list\n",
    "\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list = word_list + words_in_line\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string, converting each word to lower-case.\n",
    "    \n",
    "    :param line: a string\n",
    "    :return: a list of strings(each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"    \n",
    "    word_list = []          # accumulates words in line\n",
    "    character_list = []     # accumulates characters in word\n",
    "    for c in line:\n",
    "        if c.isalnum():\n",
    "            character_list.append(c)\n",
    "        elif len(character_list)>0:\n",
    "            word = str.join(\"\", character_list)\n",
    "            word = str.lower(word)\n",
    "            word_list.append(word)\n",
    "            character_list = []\n",
    "    if len(character_list)>0:\n",
    "        word = str.join(\"\", character_list)\n",
    "        word = str.lower(word)\n",
    "        word_list.append(word)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Operation 3: count frequency of each word ##\n",
    "##############################################\n",
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Return a list giving pairs of form: (word,frequency)\n",
    "    \n",
    "    \"\"\" \n",
    "    A= []\n",
    "    L = Counter(word_list)\n",
    "    L = dict(L)\n",
    "    return L\n",
    "\n",
    "\n",
    "\n",
    "#     L = []\n",
    "#     for new_word in word_list:\n",
    "#         for entry in L:\n",
    "#             if new_word == entry[0]:\n",
    "#                 entry[1] = entry[1] + 1\n",
    "#                 break\n",
    "#         else:\n",
    "#             L.append([new_word,1])\n",
    "#     return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Operation 4: sort words into alphabetic order             ###\n",
    "###############################################################\n",
    "def insertion_sort(A):\n",
    "    \"\"\"\n",
    "    Sort list A into order, in place.\n",
    "    \n",
    "    From Cormen/Leiserson/Rivest/Stein,\n",
    "    Introduction to Algorithms (second edition), page 17,\n",
    "    modified to adjust for fact that Python arrays use\n",
    "    0-indexing.\n",
    "    \n",
    "    \"\"\" \n",
    "    A = collections.OrderedDict(sorted(A.items()))\n",
    "    A = dict(A)\n",
    "    A = list(A.items())\n",
    "    A = [list(ele) for ele in A] \n",
    "    return A\n",
    "    \n",
    "    \n",
    "\n",
    "#     for j in range(len(A)):\n",
    "#         key = A[j]\n",
    "#         # insert A[j] into sorted sequence A[0..j-1]\n",
    "#         i = j-1\n",
    "#         while i>-1 and A[i]>key:\n",
    "#             A[i+1] = A[i]\n",
    "#             i = i-1\n",
    "#         A[i+1] = key\n",
    "#     return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## compute word frequencies for input file ##\n",
    "#############################################\n",
    "def word_frequencies_for_file(filename,verbose=False):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs\n",
    "    for the given file.\n",
    "    \n",
    "    :param filename: name of file\n",
    "    :return: list of alphabetically sorted word,frequency pairs \n",
    "    \"\"\" \n",
    "    \n",
    "    L = read_file(filename)\n",
    "    word_list = get_words_from_line_list(L)\n",
    "    A = count_frequency(word_list)\n",
    "    freq_mapping = insertion_sort(A)\n",
    "    if verbose:\n",
    "        print(\"File\",filename,\":\", len(L),\"lines,\", len(word_list),\"words,\", len(freq_mapping),\"distinct words\")\n",
    "    return freq_mapping\n",
    "\n",
    "#     line_list = read_file(filename)\n",
    "#     word_list = get_words_from_line_list(line_list)\n",
    "#     freq_mapping = count_frequency(word_list)\n",
    "#     insertion_sort(freq_mapping)\n",
    "\n",
    "\n",
    "#     return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(L1,L2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as alphabetically sorted (word,freq) pairs.\n",
    "    \n",
    "    Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "     [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0\n",
    "    \n",
    "    :param L1: vector 1\n",
    "    :param L2: vector 2\n",
    "    :return: the inner product between the two vectors\n",
    "    \"\"\"  \n",
    "    \n",
    "\n",
    "    sum = 0.0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i<len(L1) and j<len(L2):\n",
    "        # L1[i:] and L2[j:] yet to be processed\n",
    "        if L1[i][0] == L2[j][0]:\n",
    "            # both vectors have this word\n",
    "            sum += L1[i][1] * L2[j][1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i][0] < L2[j][0]:\n",
    "            # word L1[i][0] is in L1 but not L2\n",
    "            i += 1\n",
    "        else:\n",
    "            # word L2[j][0] is in L2 but not L1\n",
    "            j += 1\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_angle(L1,L2):\n",
    "    \n",
    "    \"\"\"\n",
    "    The input is a list of (word,freq) pairs, sorted alphabetically.\n",
    "    Return the angle between these two vectors.\n",
    "    \n",
    "    :param L1: vector 1\n",
    "    :param L2: vector 2\n",
    "    :return: the angle between the two vectors\n",
    "    \"\"\"  \n",
    "\n",
    "    numerator = inner_product(L1,L2)\n",
    "    denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2))\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_similarity(filename_1, filename_2, verbose=True):\n",
    "    \"\"\"\n",
    "    Pass in two filenames and compute the similarity between both documents,\n",
    "    represented as the cosine. The closer the cosine is to 1, the more similar the documents are, \n",
    "    with 1 implying identical. Zero implies virtually no difference. \n",
    "    Approaching negative 1 implies the documents are dissimilar, while -1 implies the documenst are\n",
    "    opposites.\n",
    "    \n",
    "    \n",
    "    :param filename_1: the first document\n",
    "    :param filename_2: the second document\n",
    "    :return: no return value, prints values to console\n",
    "    \"\"\"  \n",
    "    sorted_word_list_1 = word_frequencies_for_file(filename_1, verbose)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(filename_2, verbose)\n",
    "    cosine = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "    # Use f-strings; see https://realpython.com/python-f-strings/ for more information\n",
    "    if verbose:\n",
    "        print(f\"The cosine between the documents is {cosine : 0.6f}.\")\n",
    "        print(f\"The angle between the documents is {math.acos(cosine) : 0.6f} radians or {math.acos(cosine)*180/math.pi : .0f} degrees.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File assets/short.t1.txt : 200 lines, 1855 words, 772 distinct words\n",
      "File assets/short.t2.txt : 200 lines, 752 words, 334 distinct words\n",
      "The cosine between the documents is  0.712533.\n",
      "The angle between the documents is  0.777694 radians or  45 degrees.\n"
     ]
    }
   ],
   "source": [
    "document_similarity('assets/short.t1.txt','assets/short.t2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3 ms ± 160 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Perfomance of short text cases\n",
    "\n",
    "%timeit document_similarity('assets/short.t1.txt','assets/short.t2.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.2 ms ± 1.18 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Perfomance of long text cases\n",
    "\n",
    "# Note that this will take a very long time to run before you make your optimizations.\n",
    "#   Use Kernel --> Interupt in the Jupyter menu to stop execution.\n",
    "\n",
    "# Comment this out before submitting to get fast results from the autograder...\n",
    "\n",
    "%timeit document_similarity('assets/t1.verne.txt', 'assets/t2.bobsey.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32 s ± 58.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Perfomance of very long text cases\n",
    "\n",
    "# Note that this will take a very long time to run before you make your optimizations.\n",
    "#   Use Kernel --> Interupt in the Jupyter menu to stop execution.\n",
    "\n",
    "# Comment this out before submitting to get fast results from the autograder...\n",
    "\n",
    "%timeit document_similarity('assets/t5.churchill.txt', 'assets/t8.shakespeare.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b2efa089c3ef418eaec2edb0d5260401",
     "grade": true,
     "grade_id": "cell-1a-63aea205c14ed",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Result validation\n",
    "# 20 points\n",
    "\n",
    "# This check verifies that your results are correct for the short text cases.\n",
    "\n",
    "sorted_word_list_1 = word_frequencies_for_file('assets/short.t1.txt', verbose=False)\n",
    "sorted_word_list_2 = word_frequencies_for_file('assets/short.t2.txt', verbose=False)\n",
    "cosine = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "\n",
    "def close_match(a, b):\n",
    "    return round(float(a), 3) == round(float(b), 3)\n",
    "\n",
    "assert len(sorted_word_list_1) == 772\n",
    "assert len(sorted_word_list_2) == 334\n",
    "\n",
    "assert close_match(vector_angle(sorted_word_list_1,sorted_word_list_2), 0.713)\n",
    "assert close_match(math.acos(cosine), 0.778)  # Documents angle in radians\n",
    "assert close_match(math.acos(cosine)*180/math.pi, 44.559)  # Documents angle in degrees\n",
    "\n",
    "# There are no hidden autograder tests in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.94 ms ± 13.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "L = read_file('assets/short.t1.txt')\n",
    "\n",
    "%timeit get_words_from_line_list(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operation 1\n",
    "%lprun -f read_file read_file('assets/short.t1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operation 2\n",
    "L =  read_file('assets/short.t1.txt')\n",
    "%lprun -f get_words_from_line_list get_words_from_line_list(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operation 3\n",
    "word_list = get_words_from_line_list(L)\n",
    "%lprun -f count_frequency count_frequency(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operation 4\n",
    "A = count_frequency(word_list)\n",
    "%lprun -f insertion_sort insertion_sort(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute frequencies for input file\n",
    "%lprun -f word_frequencies_for_file word_frequencies_for_file('assets/short.t1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word_list_1 = word_frequencies_for_file('assets/short.t1.txt', verbose=False)\n",
    "sorted_word_list_2 = word_frequencies_for_file('assets/short.t2.txt', verbose=False)\n",
    "%lprun -f inner_product inner_product(sorted_word_list_1, sorted_word_list_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word_list_1 = word_frequencies_for_file('assets/short.t1.txt', verbose=False)\n",
    "sorted_word_list_2 = word_frequencies_for_file('assets/short.t2.txt', verbose=False)\n",
    "\n",
    "%lprun -f vector_angle vector_angle(sorted_word_list_1, sorted_word_list_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File assets/short.t1.txt : 200 lines, 1855 words, 772 distinct words\n",
      "File assets/short.t2.txt : 200 lines, 752 words, 334 distinct words\n",
      "The cosine between the documents is  0.712533.\n",
      "The angle between the documents is  0.777694 radians or  45 degrees.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%lprun -f document_similarity document_similarity('assets/short.t1.txt','assets/short.t2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_efficient_data_processing_v2_assignment4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
